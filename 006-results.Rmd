---
title: "Results"
author: "Karel Räpp, Henry Enno Turu"
date: "29 11 2020"
output: 
  bookdown::pdf_document2:
    toc: no
csl: apa.csl
bibliography: library.bib
indent: yes
fontsize: 12pt
geometry: margin = 1in
link-citations: yes
linkcolor: blue
urlcolor: blue
header-includes:
- \usepackage{placeins}
- \usepackage{setspace}
- \usepackage{chngcntr}
- \usepackage{microtype}
- \counterwithin{figure}{section}
- \counterwithin{table}{section}
- \usepackage{float}
- \usepackage{amsmath}
- \DeclareMathOperator{\logit}{logit}
---

```{r resultimport, include=F, message = F, warnings = F,echo = F}
source("functions.R")
```


# Results

Before diving to details, we plot quarterly YIV with quarterly GDP to see whether visual patterns arise. As it can be seen, the YIV seems to have a negative correlation with GDP. This relationship is especially profound  during Global Financial Crisis (around 2008-2009) when YIV surges up a bit before where a big decline in GDP happens. This is confirms our base for analysis as suggested by the literature review that indeed the treasury could have predictive ability over GDP.

```{r, message=F, warnings=F, echo = F, fig.cap="GDP Growth(%) vs 5-year Treasury Implied Volatility"}
df %>%
  select(Date, GDP, YIV) %>%
  gather(key = "variable", value = "value", -Date) %>%
  ggplot(aes(x=Date, y=value)) +
    geom_line(aes(color = variable, linetype = variable)) +
    theme_bw() +
    theme(legend.position = "bottom", legend.title = element_blank()) +
    labs(x="Date", y="Growth rate")
```

## In-sample regressions

We start our analysis by regressing YIV to GDP growth throughout different rolling periods - i.e. 4, 6, 8, 10 and 12 quarter GDP growth rolling averages (the regression formula and summary can be seen in table \@ref(tab:OLS1)). Our regression results implicate that 1 standard deviation increase in YIV is associated with a -1 * 1.31% = 1.31% decrease in gdp growth within next 4 quarters.  For predicting 12 quarters ahead (3 years), 1 standard deviation increase in YIV is associated with a -0.54 * 1.31% * 3 = 2.11% decrease in GDP growth. To illustrate the magnitude of this reduction, one should note that the average year-on-year growth rate in our sample is 2,5%.

Furthermore, it can be seen, YIV’s coefficients are significant throughout the prediction periods within 1% confidence level. The model’s R-squared gradually decreases from 39% in predicting ahead GDP growth 4 quarters’ rolling averages to 19% in predicting ahead 12 quarters’ rolling averages. These results are consistent with the paper by @Cremers2017 while the only difference is from std. error. Thus, this verifies the validity of our methodology and that the extracted data can be used to proceed with the research process. Nevertheless, as an additional robustness check to ensure that YIV predicts GDP growth and not the other way around, we run the Granger causality test by which we indeed conclude that YIV granger-caused GDP growth.

\begingroup
\linespread{1.0}\selectfont

\begin{equation}
\sum_{j=1}^{j=H}log(1+GDP_{i,t+j})/H = \alpha_{H}+ \beta_{H} \sigma_{IV,t} +\varepsilon_{t+H}
\end{equation}


```{r OLS1, message = F, warnings = F,echo = F}
regr1 <- regrs(mudelid=c("YIV"))
results1 <- regr_results(a=regr1) %>%
    round(2) %>%
    significance()

results1 %>%
  kbl(booktabs = T, longtable=T, align="c", digits=2, caption="Regression output") %>%
  kable_styling(latex_options = c("striped"), full_width = TRUE) %>%
     column_spec(1:1, width="2in")%>%
  footnote(general = "*** - p<0.01, ** - p<0.05, * - p<0.1. Reported standard error is adjusted for heteroskedasticity")

#grangertest(log_gdp ~ YIV, order=1, df)
```
\endgroup

Next, we add a dummy variable representing recessionary periods (according to the NBER classification) i.e. the dummy takes a value of 1 during recession and 0 during expansion table \@ref(tab:OLS2)). As it can be seen from the table, the dummy’s coefficient is negative and significant at 1% confidence level throughout all predicted timespans. Furthermore, adding the dummy improved R-squared significantly - 61% in predicting ahead GDP growth 4 quarters’ rolling averages when compared to 39% of respective YIV only model. The latter indicates that there is a structural break in data during recessions and that full model predictions during recessionary periods can result in poor prediction accuracy. Nevertheless, the interaction term of the dummy variable & YIV yield insignificant results. Hence, this means that recessionary period only influences the intercept, not slope of the variable.

\begingroup
\linespread{1.0}\selectfont

\begin{equation}
\sum_{j=1}^{j=H}log(1+GDP_{i,t+j})/H = \alpha_{H}+ \beta_{H} \sigma_{IV,t} + Dummy +\varepsilon_{t+H}
\end{equation}


```{r OLS2, message = F, warnings = F,echo = F}
regr2 <- regrs(mudelid=c("YIV", "dum"))
results2 <- regr_results(a=regr2) %>%
    round(2) %>%
    significance()


results2  %>%
  kbl(booktabs = T,longtable=T, align="c", digits=2, caption="Regression with state-dependency") %>%
   kable_styling(latex_options = c("striped"), full_width = TRUE) %>%
     column_spec(1:1, width="2in")%>%
       footnote(general = "*** - p<0.01, ** - p<0.05, * - p<0.1. Reported standard error is adjusted for heteroskedasticity")

#model2 <- lm(log_gdp ~ YIV + dum + YIV*dum, df)
#ols_vif_tol(model2)
```
\endgroup

Additionally, we also constructed a model with controls as regressors (Table \@ref(tab:OLS4)). The controls variables were selected among the variables described in the data section. More specifically, the following controls were selected initially: DGS1, DGS5, DGS10, DGS3MO, DGS6MO, TRM0503, TRM0506, TRM1003, TRM1006, TRM1012, STR03M, BAA-AAA, VIX, HOUSNG and GZ_SPR. However, due to multicollinearity problems among DSG and TRM controls we constructed a model for variable selection and  selected the best predictor among those groups. For selection criteria, both R-squared and Mallow’s Cp were used and according to this we chose DGS10 and TRM1012 as the best predictors out of DGS and TRM control groups. Thus, in the final regression model the following controls were included: DGS1, TRM1012, STR03M, BAA-AAA, VIX, HOUSNG and GZ_SPR.

Finally, we included all the aforementioned independent variables to one regression equation (Table \@ref(tab:OLS5)). As it can be seen, even when including the all the relevant control variables, the YIV still remains a significant predictor throughout all the periods. In the final model, the regression results implicate that 1 standard deviation increase in YIV is associated with a -0.59 * 1.31% = 0.77% decrease in gdp growth within next 4 quarters (1% confidence level). Additionally, when predicting 12 quarters ahead a 1 standard deviation increase in YIV is associated with a -0.33* 1.31% * 3 = 1.30% decrease in the next 12 quarters’ average annualized growth rate within a 5% confidence level.
The latter regression indicates that, although accounting for many of the most significant variables with regards to the GDP growth prediction, the YIV’s predictive ability still persists meaning that YIV can be considered as a solid indicator of GDP growth.


## Out of sample forecasting
### Full sample

Lastly, we were not only interested in the in-sample performance of the variable. Hence, we constructed out-of-sample regressions to compute RMSFE-s of full-sample and subsample models (results can be seen in table \@ref(fig:oosgraph)). For the out-of-sample regressions we used 5 year rolling windows and predicted ahead 1 to 12 quarters. As it can be seen from the table and graph the full-sample out-of-sample RMSFE-s rose steadily up until predicting 9 quarters ahead and then slightly dropped. In other words, the interpretation of it was that YIV-s accuracy in predicting GDP growth got worse in predicting further time periods with a slight improvement from the 10th quarter. 

### Sub-sample OOS forecasting

Next, we wanted to compare the full-sample OOS RMSFE-s with the subsample OOS RMSFE-s. As it can be seen, during the recessionary period the RMSFE is significantly higher when compared to the full-sample RMSFE. This confirms our second hypothesis i.e. the full-sample is not robust in making predictions during turbulent time periods as the accuracy of the model suffers tremendously. During the expansionary periods the OOS RMSFE improves slightly which is in line with the hypothesis as the inaccuracies of the expansionary periods are filtered out.

Figure \@ref(fig:subs) describes subsample relative RMSFE within different forecasting period. If the value is over 1, it indicates that the benchmark model(full sample model) has superior forecasting performance compared to the corresponding subsample model. Over most of the horizons, the results verify our hypothesis and are consistent with the findings of @Siliverstovs2020 - the model with reccessionary subsample has much lower forecasting performance (bigger error) compared to full-sample model, and vice versa for expansionary.


```{r subs, fig.height=3, fig.cap="Relative Recessionary & Expansionary RMSE"}
joonis  <- relative_rmsfes %>%
  melt()

ggplot(joonis, aes(Var2, value, group=factor(Var1))) +
  geom_line(aes(color=factor(Var1))) + theme_bw() +
  theme(legend.position = "bottom", legend.title = element_blank()) +
  labs(x="Time horizon", y="RMSFE value") +
  geom_hline(yintercept=1,color="black", size=1, linetype="dashed")
```



```{r message = F, warnings = F,echo = F,fig.height=2, fig.cap="Cumulative sum of squared forecast error differential (Linear model vs benchmark historic mean model"}
CSSFED_plot("hist_lm")
```


## Out-of-sample forecasting with Random Forest

```{r message = F, warnings = F,echo = F, fig.height=2, fig.cap="Cumulative sum of squared forecast error differential (Random forest model vs benchmark linear model"}
CSSFED_plot("lm_rf")
```

Lastly, we erected a random forest model to try to improve the forecasting accuracy through having non-linearity. As it can be seen from the graphs (\@ref(fig:rfjoonised1)) the performance in some cases is slightly better than OLS (e.g. during recessionary periods), however, is some cases (e.g. during expansionary periods) the model's accuracy is slightly worse. This holds also after tuning the model for number of trees. 

```{r message= F, warnings = F,echo = F,  fig.cap="Variable importance"}
p1 <- plot(variable_importance("F1"), main="H1")
p2 <- plot(variable_importance("F2"), main="H2")
p3 <- plot(variable_importance("F4"), main="H4")
p4 <- plot(variable_importance("F8"), main="H8")
grid.arrange(p1, p2, p3, p4, nrow=2)

```
