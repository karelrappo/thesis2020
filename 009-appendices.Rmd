---
title: "Appendices"
date: "12.11-2020"
output: 
  bookdown::pdf_document2:
    toc: no
csl: apa.csl
bibliography: library.bib
indent: yes
fontsize: 12pt
geometry: margin = 1in
link-citations: yes
linkcolor: blue
urlcolor: blue
header-includes:
- \usepackage{placeins}
- \usepackage{setspace}
- \usepackage{chngcntr}
- \usepackage{microtype}
- \counterwithin{figure}{section}
- \counterwithin{table}{section}
- \usepackage{float}
- \usepackage{amsmath}
- \DeclareMathOperator{\logit}{logit}
---

# Appendices
```{r run libraries, include=F}
library(stringr)
library(tidyverse)
library(summarytools)
library(kableExtra)
library(dynlm)
library(stats)
library(readr)
library(dplyr)
library(ggplot2)
library(MacroRF)
require(data.table)
library(zoo)
library(sandwich)
library(randomForest)
library(caret)
library(fbi)
library(lmtest)
library(purrr)
library(broom)
library(rollRegres)
library(modelr)
library(Metrics)
library(mltools)
library(tibble)
library(reshape2)
```


```{r child = 'Dataclean.rmd'}

```

```{r model, include=FALSE}

#pmst peaks tegema mitmetasandilise, hetkel on ainult siis nö nende erinevate H12,H18 jne kaupa. Siia peaks nüüd ühe taseme veel juurde ehitama, mis defineeriks mudelisisu, a la common regression. Siis dummy regression jne. + tuleks mõelda how newey includeda



mudelid <- c("YIV","dum", "DGS1", "DGS10", "DGS5", "DGS3MO", "TRM0503","TRM0506","TRM1003","TRM1006","TRM1012", "SRT03M", "AAA", "DBAA", "VIX", "housng")
x <- 1
df_total <- data.frame()

for (element in mudelid)
  {
  unnestedx <- df %>%
  select(H4, H6, H8, H10, H12, mudelid[1:x]) %>%
  gather(Var,Value,  -mudelid[1:x]) %>%
  nest(data=c(Value,  mudelid[1:x])) %>%
  mutate(model = map(data, ~lm(Value ~ ., data = .)),
         tidied = map(model, tidy),
         glanced = map(model, glance),
         augmented = map(model, augment),
         neweywest = map(model, ~tidy(coeftest(., vcov.=NeweyWest(., prewhite=FALSE))))) %>%
  select(-model, -data)
  
  df_total <- rbind(df_total, data.frame(unnestedx))
  x <- x+1
  remove(unnestedx)
}


regr_results <- function(a){
  results1 <- df_total[c(a:(a+4)),] %>%
    select(-augmented,-tidied, -glanced) %>%
    unnest(cols = c(neweywest)) %>%
    select(-statistic) %>%
    pivot_longer(cols=-c(1:2), names_to = "mdeea", values_to = "Delay") %>%
    mutate(x = paste(term,mdeea,sep = "_"))%>%
    select(-c(2:3)) %>%
    pivot_wider(names_from = Var, values_from = Delay) %>%
    column_to_rownames(var = "x")

  results2 <- df_total[c(a:(a+4)),] %>%
    select(-augmented,-neweywest, -tidied) %>%
    unnest(cols = c(glanced)) %>%
    select(-df, -AIC, -BIC, -deviance, -nobs, -df.residual, -logLik, -statistic, -p.value) %>%
    column_to_rownames(var = "Var")
  results2 <- as.data.frame(t(results2))

  results <- rbind(results1, results2)
  remove(results1, results2)
  rownames(results)[rownames(results) == "sigma"] <- "RMSE"
  
return(results)
}

```


```{r child = 'roll_regress.rmd', include=FALSE}

```


```{r, include=F}
order <- c("GDP", "YIV", "EMP", "CON")
statistics <- df %>%
  select(-Date, -log_gdp, -H4, -H6, -H8, -H10, -H12, - dum)%>%
  descr(
    transpose = TRUE,
    stats = c("mean","sd","min","q1","med","q3","max","n.valid"))

statistics <- statistics %>%
  mutate(Variable=rownames(statistics)) %>%
  relocate(Variable)

```

## Appendix A

```{r reg_graphs, message = F, warnings = F, echo = F}
results1 <- regr_results(a=1)
results1 <- as.data.frame(t(results1))
#results1 <- results1[c("H4", "H6", "H8", "H10", "H12"),]



regression.coefficients <- ggplot(results1, aes(x=row.names(results1), y=YIV_estimate))+ geom_bar(stat="identity", fill="steelblue")+theme_minimal()+ xlab("Quarters") + ylab("Coefficients") + labs(title = "GDP coefficients") + theme(plot.title = element_text(hjust = 0.5)) + scale_x_discrete(limits=c("H4", "H6", "H8", "H10", "H12"))

regression.fit <- ggplot(results1, aes(x=row.names(results1),y=r.squared)) + geom_bar(stat="identity", fill="steelblue")+ theme_minimal() + xlab("Quarters") + ylab("R-squared") + labs(title = "GDP R-squared") +  theme(plot.title = element_text(hjust = 0.5)) + scale_x_discrete(limits=c("H4", "H6", "H8", "H10", "H12"))

regression.fit
regression.coefficients


```

\newpage
## Appendix B

```{r GDPvsYIV, message=F, warnings=F, echo = F, fig.cap="GDP Growth(%) vs 5-year Treasury Implied Volatility"}
par(mar = c(5, 5, 3, 5))
plot(df$Date, df$YIV, type = "l", xlab = "Date", ylab = "YIV (%)", col = "blue", main = "GDP growth vs YIV")
par(new=TRUE)
plot(df$Date, df$GDP, type = "l", xaxt = "n", yaxt = "n", xlab = "", ylab = "", col = "red", lty = 2)
axis(side = 4)
mtext("GDP growth(%)", side = 4, line = 3)
legend("topleft", c("YIV", "GDP"),
       col = c("blue", "red"), lty = c(1, 2))
```

\newpage
## Appendix C

Notes: This table includes summary statistics for main variables used in our research. Statistics include mean, standard deviation,, min, 1st quartile, median, 3rd quartile, max & number of valid data points. 
In Panel A, different YIV data is summarized. 
In Panel B, we have listed the main dependent variables which are used for predictions. GDP denotes the year-on-year growth rate(quarterly data), CON denotes YOY consumption growth(monthly data), EMP describes YOY growth rate for non-farm payroll and lastly IND stands for Industrial production YOY growth (monthly data).
In Panel C, different control variables are listed: SVEN1F01 - 1 year treasury bond par yield.


```{r summarystat, message = F, warnings = F, echo = F}
statistics %>%
  kbl(booktabs = T,  longtable=T, align="c", digits=2, caption="Summary Statistics") %>%
  kable_styling(latex_options = c("striped","repeat_header")) %>%
  group_rows("Panel A: YIV",1,1, latex_align="c") %>%
  group_rows("Panel B: Dependent Variables",2,5, latex_align="c") %>%
  group_rows("Panel C: Control Variables",6,7, latex_align="c") %>%
  footnote(general = "Additional control variables will be added upon construction. Furthermore, currently the frequency of the datasets differs for different variables but this will be addressed in the research process.", threeparttable=T)

  

```
\newpage
## Appendix D. 

Notes: This table depicts the output of regression with YIV as only independent variable. 

\begin{equation}
\sum_{j=1}^{j=H}log(1+GDP_{i,t+j})/H = \alpha_{H}+ \beta_{H} \sigma_{IV,t}^{INT} +\varepsilon_{t+H}
\end{equation}

```{r tableOLS, message = F, warnings = F,echo = F}
results1 <- regr_results(a=1)
results1 %>%
  kbl(booktabs = T, longtable=T, align="c", digits=2, caption="Regression output") %>%
  kable_styling(latex_options = c("striped"), full_width = TRUE) %>%
  pack_rows("Panel A: YIV",1,1, latex_align="c") %>%
  footnote(general = "*** - p<0.01, ** - p<0.05, * - p<0.1. Reported standard error is adjusted for heteroskedasticity")

```
\newpage
## Appendix E. 

Notes: This table includes regression using GDP & YIV. Controls will be added during research process. The equation for the regression is the following:

\begin{equation}
\sum_{j=1}^{j=H}log(1+GDP_{i,t+j})/H = \alpha_{H}+ \beta_{H} \sigma_{IV,t}^{INT} + Dummy +\varepsilon_{t+H}
\end{equation}

```{r mingiOLS, message = F, warnings = F,echo = F}
df_results_d <- regr_results(a=6)

df_results_d  %>%
  kbl(booktabs = T,longtable=T, align="c", digits=2, caption="Regression with state-dependency") %>%
   kable_styling(latex_options = c("striped"), full_width = TRUE) %>%
     pack_rows("Panel A",1,1, latex_align="c") %>%
       footnote(general = "*** - p<0.01, ** - p<0.05, * - p<0.1. Reported standard error is adjusted for heteroskedasticity")

```

\newpage
## Appendix F. 

Notes: This table includes regression using GDP & YIV and controls.

\begin{equation}
\sum_{j=1}^{j=H}log(1+GDP_{i,t+j})/H = \alpha_{H}+ \beta_{H} \sigma_{IV,t}^{INT} + Dummy +\varepsilon_{t+H}
\end{equation}

```{r mingiuusOLS, message = F, warnings = F,echo = F}
df_results_all <- regr_results(a=76)

df_results_all  %>%
  kbl(booktabs = T,longtable=T, align="c", digits=2, caption="Regression with state-dependency") %>%
   kable_styling(latex_options = c("striped"), full_width = TRUE) %>%
     pack_rows("Panel A",1,1, latex_align="c") %>%
       footnote(general = "*** - p<0.01, ** - p<0.05, * - p<0.1. Reported standard error is adjusted for heteroskedasticity")

```




\newpage
## Appendix H. 

```{r roll_regress, message = F, warnings = F,echo = F}
df_resultss %>%
  kbl() %>%
  kable_styling()

df_results <- transpose(df_resultss)

df_resultss2 <- melt(df_resultss)
df_resultss2$rowid <- c("Out-of-sample RMSFE", "Recessionary", "Expansionary" ,"Naive", "TRM", "CRS")

ggplot(df_resultss2, aes(variable, value, group=factor(rowid))) + geom_line(aes(color=factor(rowid)))

```
\newpage


```{r randomforest, message=F, warnings=F,echo = F, include=F}
# train <- dataset[,2:22]
# test <- dataset[1:15,2:22]
# #The Random Forest
# train[,1:14] <- sapply(train[,1:14], as.numeric) #Convert all predictors to numeric variables
# set.seed(131) #Set randomizing seed for replication study
# 
# #The Random Forest Algorithm
# library(randomForest)
# gdp.rf <- randomForest(GDPC1 ~ .
# , data=train, importance=TRUE, na.action=na.omit)
# print(gdp.rf)
# #Variable importance measure
# imp <- importance(gdp.rf, type = 1)
# round(imp, 3)
# varImpPlot(gdp.rf)
# #Prediction
# test[1:15,1:114] <- sapply(test[1:15,1:114], as.numeric)
# pred.rf <- predict(gdp.rf, newdata=test, n.ahead=15)
# pred.rf
# #RMSE
# RMSE(test$GDPC1, pred.rf)
#  
```
\newpage

## APPENDIX I. DATA ACQUISITION

As researchers typically do not typically post underlying data with their research, various plot digitizers have seen an exponential increase in use. @Drevon2017 researched intercoder reliability, during which over 3500 data points were extracted with WebPlotDigitizer from 36 different graphs. Nevertheless, they controlled the validity of the results and concluded that there was a near perfect correlation (r=0.989 with p-value <0.01) between extracted and actual data. Nevertheless, the limitations mentioned highlight coders previous experience with plot-digitizing tools.

Furthermore, @Burda2017 also highlight that systematic reviewers often tend to have data constraints which is why plot digitizers are of a great help. They estimated data using WebPlotDigitizer and conclude that the extraction done by different coders was consistent; nevertheless, in the case of continuous data (compared to event data), the distribution varied more. Whatsoever, the intreclass coefficient for both types of plots was over 95%.

We also used the WebPlotDigitzer in our research and as validity test extracted GDP from the same graph as YIV time series & plotted it with actuals - see the graph below.

```{r actualvsextracted, message=F, warnings=F,echo = F, fig.cap = "Actual GDP growth vs extracted GDP growth in % using WebPlotDigitizer"}
GDP_data <- read_csv("data/actualvsplot.csv")

par(mar = c(5, 5, 3, 5))
plot(GDP_data$Date, GDP_data$Actual, type = "l", xlab = "Date", ylab = "Actual GDP Growth", col = "blue", main = "Actual GDP vs extracted GDP growth")
par(new=TRUE)
plot(GDP_data$Date, GDP_data$Extracted, type = "l", xaxt = "n", yaxt = "n", xlab = "", ylab = "", col = "red", lty = 2)
legend("bottomleft", c("Actual", "Extracted"),
       col = c("blue", "red"), lty = c(1, 2))
```



