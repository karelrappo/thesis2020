---
title: "Appendices"
date: "12.11-2020"
output: 
  bookdown::pdf_document2:
    toc: no
csl: apa.csl
bibliography: library.bib
indent: yes
fontsize: 12pt
geometry: margin = 1in
link-citations: yes
linkcolor: blue
urlcolor: blue
header-includes:
- \usepackage{placeins}
- \usepackage{setspace}
- \usepackage{chngcntr}
- \usepackage{microtype}
- \counterwithin{figure}{section}
- \counterwithin{table}{section}
- \usepackage{float}
- \usepackage{amsmath}
- \DeclareMathOperator{\logit}{logit}
---

# Appendices
```{r run libraries, include=F}
library(stringr)
library(tidyverse)
library(summarytools)
library(kableExtra)
library(dynlm)
library(stats)
library(readr)
library(dplyr)
library(ggplot2)
library(MacroRF)
require(data.table)
library(zoo)
library(sandwich)
library(randomForest)
library(caret)
library(fbi)
library(lmtest)
library(purrr)
library(broom)
library(rollRegres)
library(modelr)
library(Metrics)
library(mltools)
library(tibble)
library(reshape2)
```


```{r child = 'Dataclean.rmd'}

```

```{r}

#pmst peaks tegema mitmetasandilise, hetkel on ainult siis nö nende erinevate H12,H18 jne kaupa. Siia peaks nüüd ühe taseme veel juurde ehitama, mis defineeriks mudelisisu, a la common regression. Siis dummy regression jne. + tuleks mõelda how newey includeda

mudelid <- c("YIV","dum", "DGS10", "DGS1")
x <- 1
df_total <- data.frame()

for (element in mudelid)
  {
  unnestedx <- df %>%
  select(H12, H18, H24, H30, H36, mudelid[1:x]) %>%
  gather(Var,Value,  -mudelid[1:x]) %>%
  nest(data=c(Value,  mudelid[1:x])) %>%
  mutate(model = map(data, ~lm(Value ~ ., data = .)),
         tidied = map(model, tidy),
         glanced = map(model, glance),
         augmented = map(model, augment),
         neweywest = map(model, ~tidy(coeftest(., vcov.=NeweyWest(., prewhite=FALSE))))) %>%
  select(-model, -data)
  
  df_total <- rbind(df_total, data.frame(unnestedx))
  x <- x+1
  remove(unnestedx)
}

regr_results <- function(a){
  results <- df_total[c(a:(a+4)),] %>%
    select(-augmented,-neweywest) %>%
    unnest(cols = c(glanced)) %>%
    select(-df, -AIC, -BIC, -deviance, -nobs, -df.residual, -logLik, -statistic, -p.value) %>%
    unnest(cols = c(tidied)) %>%
    filter( term != "(Intercept)") %>%
    select(-term, -statistic) %>%
    column_to_rownames(var = "Var") %>%
    round(2) %>%
    rename(RMSE=sigma)
  results$'Significance'[results$'p.value' >= 0] <- "aaa"
  results$'Significance'[results$'p.value' > 0.01] <- "aa"
  results$'Significance'[results$'p.value' > 0.05] <- "a"
  results$'Significance'[results$'p.value' > 0.1] <- "NA"
  results$'Significance' <- gsub("a", "*", results$'Significance')
return(results)
}
```


```{r child = 'roll_regress.rmd'}

```





```{r, include=F}

# define a function to get coefficients from linear regression
do_regression2 <- function(var)
  { # var - the name of the variable to be regressed
    res <- lm(as.formula(paste0(var, "~ YIV +dum")), df) # run linear regression
    coefs <- c("Intercept" = summary(res)$coefficients[1,1], 
               "Beta" = summary(res)$coefficients[-1,1], 
               "Newey"=NeweyWest(res)[-1,1],
               "R-Squared"= summary(res)$r.squared*100,
               "Adj. R2"=summary(res)$adj.r.squared*100,  
               "p-value"= summary(res)$coefficients[-1,4],
               "RMSE" = sigma(res),
               "Std" = coeftest(res, vcov=vcovHC(res, type ="HC1"))[-1, "Std. Error"])
  return(coefs)
  }

df_results_dummy <- as.data.frame(t(sapply(colnames(df)[24:28], do_regression2)))

df_results_dummy <- df_results_dummy %>%
  round(2)

  
```



```{r, include=F}
order <- c("GDP", "YIV", "EMP", "CON")
statistics <- df %>%
  select(-Date, -log_gdp, -H12, -H18, -H24, -H30, -H36, - dum)%>%
  descr(
    transpose = TRUE,
    stats = c("mean","sd","min","q1","med","q3","max","n.valid"))

statistics <- statistics %>%
  mutate(Variable=rownames(statistics)) %>%
  relocate(Variable)

```
\newpage
## Appendix A

```{r reg_graphs, message = F, warnings = F, echo = F}
results1 <- regr_results(a=1)

regression.coefficients <- ggplot(results1, aes(x=row.names(results1), y=estimate))+ geom_bar(stat="identity", fill="steelblue")+theme_minimal()+ xlab("Quarters") + ylab("Coefficients") + labs(title = "GDP coefficients") + theme(plot.title = element_text(hjust = 0.5))
                                                                                                                                                                      
regression.fit <- ggplot(results1, aes(x=row.names(results1),y=r.squared)) + geom_bar(stat="identity", fill="steelblue")+ theme_minimal() + xlab("Quarters") + ylab("R-squared") + labs(title = "GDP R-squared") +  theme(plot.title = element_text(hjust = 0.5))
regression.fit
regression.coefficients

```

\newpage
## Appendix B

```{r GDPvsYIV, message=F, warnings=F, echo = F, fig.cap="GDP Growth(%) vs 5-year Treasury Implied Volatility"}
par(mar = c(5, 5, 3, 5))
plot(df$Date, df$YIV, type = "l", xlab = "Date", ylab = "YIV (%)", col = "blue", main = "GDP growth vs YIV")
par(new=TRUE)
plot(df$Date, df$GDP, type = "l", xaxt = "n", yaxt = "n", xlab = "", ylab = "", col = "red", lty = 2)
axis(side = 4)
mtext("GDP growth(%)", side = 4, line = 3)
legend("topleft", c("YIV", "GDP"),
       col = c("blue", "red"), lty = c(1, 2))
```

\newpage
## Appendix C

Notes: This table includes summary statistics for main variables used in our research. Statistics include mean, standard deviation,, min, 1st quartile, median, 3rd quartile, max & number of valid data points. 
In Panel A, different YIV data is summarized. 
In Panel B, we have listed the main dependent variables which are used for predictions. GDP denotes the year-on-year growth rate(quarterly data), CON denotes YOY consumption growth(monthly data), EMP describes YOY growth rate for non-farm payroll and lastly IND stands for Industrial production YOY growth (monthly data).
In Panel C, different control variables are listed: SVEN1F01 - 1 year treasury bond par yield.


```{r summarystat, message = F, warnings = F, echo = F}
statistics %>%
  kbl(booktabs = T,  longtable=T, align="c", digits=2, caption="Summary Statistics") %>%
  kable_styling(latex_options = c("striped","repeat_header")) %>%
  group_rows("Panel A: YIV",1,1, latex_align="c") %>%
  group_rows("Panel B: Dependent Variables",2,5, latex_align="c") %>%
  group_rows("Panel C: Control Variables",6,7, latex_align="c") %>%
  footnote(general = "Additional control variables will be added upon construction. Furthermore, currently the frequency of the datasets differs for different variables but this will be addressed in the research process.", threeparttable=T)

  

```
\newpage
## Appendix D. 

Notes: This table includes regression using GDP & YIV. Controls will be added during research process. The equation for the regression is the following:

\begin{equation}
\sum_{j=1}^{j=H}log(1+GDP_{i,t+j})/H = \alpha_{H}+ \beta_{H} \sigma_{IV,t}^{INT} + Controls +\varepsilon_{t+H}
\end{equation}

```{r tableOLS, message = F, warnings = F,echo = F}
results1 %>%
  t()%>%
  kbl(booktabs = T, longtable=T, align="c", digits=2, caption="Regression output") %>%
  kable_styling(latex_options = c("striped"), full_width = TRUE) %>%
  pack_rows("Panel A: YIV",1,1, latex_align="c") %>%
  footnote(general = "*** - p<0.01, ** - p<0.05, * - p<0.1. Reported standard error is adjusted for heteroskedasticity")

```
\newpage
## Appendix E. 

Notes: This table includes regression using GDP & YIV. Controls will be added during research process. The equation for the regression is the following:

\begin{equation}
\sum_{j=1}^{j=H}log(1+GDP_{i,t+j})/H = \alpha_{H}+ \beta_{H} \sigma_{IV,t}^{INT} + Dummy +\varepsilon_{t+H}
\end{equation}

```{r mingiOLS, message = F, warnings = F,echo = F}

df_results_dummy  %>%
  t() %>%
  kbl(booktabs = T,longtable=T, align="c", digits=2, caption="Regression with state-dependency") %>%
   kable_styling(latex_options = c("striped"), full_width = TRUE) %>%
     pack_rows("Panel A",1,1, latex_align="c") %>%
       footnote(general = "*** - p<0.01, ** - p<0.05, * - p<0.1. Reported standard error is adjusted for heteroskedasticity")

```
\newpage
## Appendix F. 

```{r roll_regress, message = F, warnings = F,echo = F}
df_resultss %>%
  kbl() %>%
  kable_styling()

df_results <- transpose(df_resultss)

df_resultss2 <- melt(df_resultss)
df_resultss2$rowid <- c("Out-of-sample RMSFE", "Recessionary", "Expansionary" ,"Naive", "TRM", "CRS")

ggplot(df_resultss2, aes(variable, value, group=factor(rowid))) + geom_line(aes(color=factor(rowid)))

```
\newpage


```{r randomforest, message=F, warnings=F,echo = F, include=F}
# train <- dataset[,2:22]
# test <- dataset[1:15,2:22]
# #The Random Forest
# train[,1:14] <- sapply(train[,1:14], as.numeric) #Convert all predictors to numeric variables
# set.seed(131) #Set randomizing seed for replication study
# 
# #The Random Forest Algorithm
# library(randomForest)
# gdp.rf <- randomForest(GDPC1 ~ .
# , data=train, importance=TRUE, na.action=na.omit)
# print(gdp.rf)
# #Variable importance measure
# imp <- importance(gdp.rf, type = 1)
# round(imp, 3)
# varImpPlot(gdp.rf)
# #Prediction
# test[1:15,1:114] <- sapply(test[1:15,1:114], as.numeric)
# pred.rf <- predict(gdp.rf, newdata=test, n.ahead=15)
# pred.rf
# #RMSE
# RMSE(test$GDPC1, pred.rf)
#  
```





